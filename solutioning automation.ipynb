{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime, timedelta, time, date\n",
    "import re\n",
    "\n",
    "import xlsxwriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the path of input files -> rbd=raw billing data, ra=route analysis, ba=BA raw report\n",
    "path_rbd= 'D:/solutioning/Morgan Stanley Blr/RBD.csv'\n",
    "path_ba= 'D:/solutioning/Morgan Stanley Blr/BA.csv'\n",
    "path_ra= 'D:/solutioning/Morgan Stanley Blr/RA.csv'\n",
    "\n",
    "# Converting cab type to seating capacity. If capacity can be inferred from cab type column leave it as '{}'\n",
    "rbd_cab_capacity_mapping = {}\n",
    "ra_cab_capacity_mapping = {'Toyota Etios':4, 'Toyota Innova':6, 'StandBy':4}\n",
    "\n",
    "# define the start and end date for the seat utilization analysis\n",
    "seat_util_start_date = datetime.strptime(\"03-02-2020\", \"%d-%m-%Y\")\n",
    "seat_util_end_date = datetime.strptime(\"07-02-2020\", \"%d-%m-%Y\")\n",
    "\n",
    "# start and end date to analyse the commercials deployed against vendor and contract\n",
    "commercial_start_date = datetime.strptime(\"03-02-2020\", \"%d-%m-%Y\")\n",
    "commercial_end_date = datetime.strptime(\"07-02-2020\", \"%d-%m-%Y\")\n",
    "\n",
    "# based on trip status, which all trips are to be included in the analysis of fleet mix and commercials\n",
    "trips_to_include = ['Trip Completed', 'Trip Marked Noshow', 'Trip in Progress', 'Trip cancelled from dashboard']\n",
    "\n",
    "# define where the result file needs to be stored\n",
    "output_path = 'D:/solutioning/Morgan Stanley Blr/result.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### RBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_rbd_jan = pd.read_csv(\"D:/solutioning/Office/RBD_Jan.csv\", infer_datetime_format=True)\n",
    "# df_rbd_feb = pd.read_csv(\"D:/solutioning/infosys-iblr/RBD_Feb.csv\", infer_datetime_format=True)\n",
    "# df_rbd_mar = pd.read_csv(\"D:/solutioning/Office/RBD_Mar.csv\", infer_datetime_format=True)\n",
    "# df_rbd_apr = pd.read_csv(\"D:/solutioning/Office/RBD_Apr.csv\", infer_datetime_format=True)\n",
    "# df_rbd_may = pd.read_csv(\"D:/solutioning/Office/RBD_May.csv\", infer_datetime_format=True)\n",
    "# df_rbd_jun = pd.read_csv(\"D:/solutioning/Office/RBD_Jun.csv\", infer_datetime_format=True)\n",
    "# df_rbd_jul = pd.read_csv(\"D:/solutioning/Genpact-Hyd/RBD_Jul.csv\", infer_datetime_format=True)\n",
    "# df_rbd_aug = pd.read_csv(\"D:/solutioning/Office/RBD_Aug.csv\", infer_datetime_format=True)\n",
    "# df_rbd_sep = pd.read_csv(\"D:/solutioning/Office/RBD_Sep.csv\", infer_datetime_format=True)\n",
    "# df_rbd_oct = pd.read_csv(\"D:/solutioning/Wipro-SJP/RBD_Oct.csv\", infer_datetime_format=True)\n",
    "# df_rbd_nov = pd.read_csv(\"D:/solutioning/Office/RBD_Nov.csv\", infer_datetime_format=True)\n",
    "# df_rbd_dec = pd.read_csv(\"D:/solutioning/Office/RBD_Dec.csv\", infer_datetime_format=True)\n",
    "\n",
    "# df_rbd = pd.concat([df_rbd_jul], ignore_index=True, sort=False)\n",
    "# del [df_rbd_jul]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rbd = pd.read_csv(path_rbd, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date1(x):\n",
    "    if x=='':\n",
    "        return np.nan\n",
    "    else:\n",
    "        format = '%d-%b-%y'\n",
    "        return datetime.strptime(x, format)\n",
    "\n",
    "def datentime1(x):\n",
    "    if x=='':\n",
    "        return x\n",
    "    else:\n",
    "        if len(x)>18:\n",
    "            format = '%d-%b-%y %H:%M:%S'\n",
    "            return datetime.strptime(x, format)\n",
    "        elif len(x)<18:\n",
    "            format = '%d-%b-%y %H:%M'\n",
    "            return datetime.strptime(x, format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the data type of Leg date, duty start and duty end. \n",
    "\n",
    "df_rbd['Leg Date'] = df_rbd['Leg Date'].replace(np.nan, '').apply(date1)\n",
    "\n",
    "for x in ['Duty Start', 'Duty End']:\n",
    "    df_rbd[x] = df_rbd[x].apply(datentime1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add column for cab capcity \n",
    "if len(rbd_cab_capacity_mapping) == 0:\n",
    "    df_rbd['Cab Capacity'] = df_rbd['Contract'].replace(np.nan,\"\").apply(lambda x: int(re.findall(\"\\d+\", \n",
    "                                                                                            x)[0]) if len(x)>0 else None)\n",
    "else:\n",
    "    df_rbd['Cab Capacity'] = df_rbd['Contract'].replace(np.nan,'').apply(lambda x: rbd_cab_capacity_mapping[x] if len(x)>0 else None)                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a weekday column to the table\n",
    "\n",
    "def day_of_week(x):\n",
    "    y = {0:'Mon', 1:'Tue', 2:'Wed', 3:'Thu', 4:'Fri', 5:'Sat', 6:'Sun'}\n",
    "    if x!=x:            #null values are not equal to themselves\n",
    "        return ''\n",
    "    else:\n",
    "        return y[x.weekday()]\n",
    "\n",
    "df_rbd['Weekday'] = df_rbd['Leg Date'].apply(day_of_week)\n",
    "\n",
    "# excluding weekends\n",
    "\n",
    "# df_rbd_wkday = df_rbd.dropna(subset=['Leg Date'])\n",
    "# df_rbd_wkday = df_rbd_wkday[df_rbd_wkday['Weekday'].apply(lambda x: True if x in ['Mon', 'Tue', \n",
    "#                                                                                        'Wed', 'Thu', 'Fri'] else False)]\n",
    "# df_rbd = df_rbd_wkday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### BA Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ba_jan = pd.read_csv(\"D:/solutioning/anushka/iqvia/Nov BAR.csv\", infer_datetime_format=True)\n",
    "# df_ba_feb = pd.read_csv(\"D:/solutioning/infosys-iblr/BA_Feb.csv\", infer_datetime_format=True)\n",
    "# df_ba_mar = pd.read_csv(\"D:/solutioning/Office/BA_Mar.csv\", infer_datetime_format=True)\n",
    "# df_ba_apr = pd.read_csv(\"D:/solutioning/Office/BA_Apr.csv\", infer_datetime_format=True)\n",
    "# df_ba_may = pd.read_csv(\"D:/solutioning/Office/BA_May.csv\", infer_datetime_format=True)\n",
    "# df_ba_jun = pd.read_csv(\"D:/solutioning/Office/BA_Jun.csv\", infer_datetime_format=True)\n",
    "# df_ba_jul = pd.read_csv(\"D:/solutioning/Office/BA_Jul.csv\", infer_datetime_format=True)\n",
    "# df_ba_aug = pd.read_csv(\"D:/solutioning/Office/BA_Aug.csv\", infer_datetime_format=True)\n",
    "# df_ba_sep = pd.read_csv(\"D:/solutioning/Office/BA_Sep.csv\", infer_datetime_format=True)\n",
    "# df_ba_oct = pd.read_csv(\"D:/solutioning/Wipro-SJP/BA_Oct.csv\", infer_datetime_format=True)\n",
    "# df_ba_nov = pd.read_csv(\"D:/solutioning/Office/BA_Nov.csv\", infer_datetime_format=True)\n",
    "# df_ba_dec = pd.read_csv(\"D:/solutioning/Office/BA_Dec.csv\", infer_datetime_format=True)\n",
    "\n",
    "# df_ba = pd.concat([df_ba_feb], ignore_index=True, sort=False)\n",
    "# del [df_ba_feb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ba = pd.read_csv(path_ba, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date(x):\n",
    "    format = '%b %d, %Y'\n",
    "    return datetime.strptime(x, format)\n",
    "\n",
    "def datentime(x):\n",
    "    format = '%b %d,%Y %H:%M'\n",
    "    if x=='':\n",
    "        return x\n",
    "    else: \n",
    "        return datetime.strptime(x, format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the date and the five datetimes in the report to datetime\n",
    "\n",
    "df_ba['Date'] = df_ba['Date'].apply(date)\n",
    "\n",
    "for x in ['Planned Pickup Time', 'Driver Report Time', 'Actual Pickup Time', 'Planned Drop Time', 'Actual Drop Time']:\n",
    "    df_ba[x] = df_ba[x].replace('--', '').apply(datentime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a weekday column to the table\n",
    "\n",
    "df_ba['Weekday'] = df_ba['Date'].apply(day_of_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate direction and shift time into a column named 'Shift'\n",
    "\n",
    "df_ba['Shift'] = df_ba['Direction'].str.cat(df_ba['Shift Type/Time'], sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RA Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ra_jan = pd.read_csv(\"D:/solutioning/Morgan Stanley Mum/RA_Nirlon.csv\", infer_datetime_format=True)\n",
    "# df_ra_feb = pd.read_csv(\"D:/solutioning/Morgan Stanley Mum/RA_GKC.csv\", infer_datetime_format=True)\n",
    "# df_ra_mar = pd.read_csv(\"D:/solutioning/Morgan Stanley Mum/RA_WeWork.csv\", infer_datetime_format=True)\n",
    "# df_ra_apr = pd.read_csv(\"D:/solutioning/Office/RA_Apr.csv\", infer_datetime_format=True)\n",
    "# df_ra_may = pd.read_csv(\"D:/solutioning/Office/RA_May.csv\", infer_datetime_format=True)\n",
    "# df_ra_jun = pd.read_csv(\"D:/solutioning/Office/RA_Jun.csv\", infer_datetime_format=True)\n",
    "# df_ra_jul = pd.read_csv(\"D:/solutioning/Office/RA_Jul.csv\", infer_datetime_format=True)\n",
    "# df_ra_aug = pd.read_csv(\"D:/solutioning/Office/RA_Aug.csv\", infer_datetime_format=True)\n",
    "# df_ra_sep = pd.read_csv(\"D:/solutioning/Office/RA_Sep.csv\", infer_datetime_format=True)\n",
    "# df_ra_oct = pd.read_csv(\"D:/solutioning/Wipro-SJP/RA_Oct.csv\", infer_datetime_format=True)\n",
    "# df_ra_nov = pd.read_csv(\"D:/solutioning/Office/RA_Nov.csv\", infer_datetime_format=True)\n",
    "# df_ra_dec = pd.read_csv(\"D:/solutioning/Office/RA_Dec.csv\", infer_datetime_format=True)\n",
    "\n",
    "# df_ra = pd.concat([df_ra_feb, df_ra_jan, df_ra_mar], ignore_index=True, sort=False)\n",
    "# del [df_ra_feb, df_ra_jan, df_ra_mar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ra = pd.read_csv(path_ra, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding the cab capacity column\n",
    "if len(ra_cab_capacity_mapping) == 0:\n",
    "    df_ra['Cab Capacity'] = df_ra['Cab Type'].apply(lambda x: int(re.findall(\"\\d+\", x)[0]))\n",
    "else:\n",
    "    df_ra['Cab Capacity'] = df_ra['Cab Type'].apply(lambda x: ra_cab_capacity_mapping[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fleet Mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Seat Utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider all trips where planned trip employee is not 0\n",
    "temp = df_rbd[(df_rbd['Planned Trip Employees']!=0) & (df_rbd['Leg Type']=='Trip')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SU1 = sum of planned trip employees\n",
    "\n",
    "SU1 = temp[(temp['Leg Date']>=seat_util_start_date) & (temp['Leg Date']<=seat_util_end_date)].pivot_table(\n",
    "        values='Planned Trip Employees', index=['Leg Date', 'Trip Type'], columns='Cab Capacity', aggfunc='sum')\n",
    "\n",
    "# SU2 = distinct count of trip ids\n",
    "\n",
    "SU2 = temp[(temp['Leg Date']>=seat_util_start_date) & (temp['Leg Date']<=seat_util_end_date)].pivot_table(\n",
    "        values='Trip Id', index=['Leg Date', 'Trip Type'], columns='Cab Capacity', aggfunc='count')\n",
    "SU = SU1/SU2\n",
    "\n",
    "# finding the seat utilization percentage\n",
    "\n",
    "for i in list(np.arange(len((SU).columns))):\n",
    "    SU.iloc[:,i] = SU.iloc[:,i]/SU.columns[i]*100\n",
    "\n",
    "# concatenating all the table i.e #trips, #employees and seat utilization percentage.\n",
    "\n",
    "temp_su = pd.concat([SU1, SU2, SU], axis=1, copy=False, keys=['employees', 'trips', 'seat util %'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a concatenated table containing capacity, employees travelling and the max deviation for the trip against route ID\n",
    "\n",
    "temp = pd.concat([df_ra.groupby('RouteId')['EmpID'].count(), df_ra.groupby('RouteId')['Extra distance'].max(),\n",
    "                   df_ra.groupby('RouteId')['Cab Capacity'].mean()], axis=1, copy=False)\n",
    "temp.rename(columns={'EmpID':'#employees'}, inplace=True, copy=False)\n",
    "temp.reset_index(inplace=True)\n",
    "\n",
    "# final tabular format of the information\n",
    "\n",
    "temp = temp.groupby(['Cab Capacity', '#employees'])['Extra distance'].mean()\n",
    "temp_dev = temp.unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Fleet mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chopping dataframe containing only required trips based on the trip status\n",
    "\n",
    "temp = df_rbd[df_rbd['Trip Status'].apply(lambda x: True if x in trips_to_include else False)]\n",
    "\n",
    "# concatenating the 2 tables containing #unique cabs and %of the overall trips done cab capacity wise\n",
    "\n",
    "temp_fm = pd.concat([temp.groupby('Cab Capacity')['Registration'].nunique(), \n",
    "                  ((temp.groupby('Cab Capacity')['Trip Id'].count()/temp['Trip Id'].count())*100)], axis=1, \n",
    "                    copy=False).rename(columns={'Registration':'#unique cabs', 'Trip Id':'%of trips done'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bill Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Trip Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user defined slabs\n",
    "user_defined_km_slabs = [10,15,20,25,30,40,50,60,150]\n",
    "\n",
    "# taking completed trips\n",
    "\n",
    "temp = df_rbd[df_rbd['Trip Status']=='Trip Completed']\n",
    "# inserting 0 in slabs to create bins for classification\n",
    "user_defined_km_slabs.insert(0, 0)\n",
    "\n",
    "# find number of trips by using cut function bins and applying value_counts to it\n",
    "\n",
    "temp = pd.concat([pd.DataFrame(user_defined_km_slabs), pd.cut(temp['Leg Distance'], bins=user_defined_km_slabs, \n",
    "                                     right=False).value_counts().sort_index().reset_index(drop=True)], axis=1, copy=False)\n",
    "\n",
    "# working on the presentation side\n",
    "\n",
    "temp.drop(columns=[0], axis=1, inplace=True)\n",
    "user_defined_km_slabs.remove(0)\n",
    "temp = temp.dropna()\n",
    "temp.set_axis(list(map(lambda x: str(x)+' km bin', user_defined_km_slabs)), inplace=True)\n",
    "temp_td = temp.rename(columns={'Leg Distance':'# of trips'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Cab Capacity</th>\n",
       "      <th>4.0</th>\n",
       "      <th>6.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>km brackets</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>[0, 10)</td>\n",
       "      <td>1979</td>\n",
       "      <td>1648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[10, 15)</td>\n",
       "      <td>1721</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[15, 20)</td>\n",
       "      <td>1510</td>\n",
       "      <td>803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[20, 25)</td>\n",
       "      <td>1116</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[25, 30)</td>\n",
       "      <td>751</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[30, 40)</td>\n",
       "      <td>609</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[40, 50)</td>\n",
       "      <td>86</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[50, 60)</td>\n",
       "      <td>88</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>[60, 150)</td>\n",
       "      <td>52</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Cab Capacity   4.0   6.0\n",
       "km brackets             \n",
       "[0, 10)       1979  1648\n",
       "[10, 15)      1721   921\n",
       "[15, 20)      1510   803\n",
       "[20, 25)      1116   562\n",
       "[25, 30)       751   287\n",
       "[30, 40)       609   284\n",
       "[40, 50)        86    31\n",
       "[50, 60)        88    24\n",
       "[60, 150)       52    18"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# user defined slabs\n",
    "user_defined_km_slabs = [10,15,20,25,30,40,50,60,150]\n",
    "\n",
    "# taking completed trips\n",
    "\n",
    "temp = df_rbd[df_rbd['Trip Status']=='Trip Completed']\n",
    "# inserting 0 in slabs to create bins for classification\n",
    "user_defined_km_slabs.insert(0, 0)\n",
    "\n",
    "# find number of trips by using cut function bins and applying value_counts to it\n",
    "\n",
    "temp = pd.concat([pd.cut(temp['Leg Distance'], bins=user_defined_km_slabs, \n",
    "                         right=False).rename('km brackets'), temp], axis=1, copy=False)\n",
    "#temp = pd.concat([pd.DataFrame(user_defined_km_slabs), pd.cut(temp['Leg Distance'], bins=user_defined_km_slabs, \n",
    "#                                     right=False).value_counts().sort_index()], axis=1, copy=False)\n",
    "\n",
    "temp = temp.groupby('Cab Capacity')['km brackets'].value_counts().sort_index()\n",
    "temp.unstack(level=0)\n",
    "# working on the presentation side\n",
    "\n",
    "# temp.drop(columns=[0], axis=1, inplace=True)\n",
    "# user_defined_km_slabs.remove(0)\n",
    "# temp = temp.dropna()\n",
    "# temp.set_axis(list(map(lambda x: str(x)+' km bin', user_defined_km_slabs)), inplace=True)\n",
    "# temp_td = temp.rename(columns={'Leg Distance':'# of trips'})\n",
    "# temp_td"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Trips per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering out the completed trips\n",
    "\n",
    "temp = df_rbd[df_rbd['Trip Status']=='Trip Completed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe '_' that maps trips per day against each cab registration\n",
    "\n",
    "_ = (temp.groupby('Registration')['Trip Id'].count())/(temp.groupby('Registration')['Leg Date'].nunique())\n",
    "\n",
    "# now adding columns containing info about capacity, vendor and contract against each registration\n",
    "\n",
    "temp = pd.merge(_.reset_index(), temp.drop_duplicates(subset='Registration')[['Registration',\n",
    "                                        'Vendor', 'Contract', 'Cab Capacity']], how='inner', copy=False, on='Registration')\n",
    "temp.rename(columns={0:'trips per day'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# breaking into user defined slabs\n",
    "\n",
    "user_defined_trip_slabs = [0,2,4,6,8]\n",
    "temp['trip slab'] = pd.cut(temp['trips per day'], bins=user_defined_trip_slabs, right=False)\n",
    "\n",
    "# final tabular form \n",
    "\n",
    "temp_tpd = temp.pivot_table(values='Registration', columns='Cab Capacity', index='trip slab', aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### KM per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip km per day\n",
    "\n",
    "\n",
    "temp = df_rbd[df_rbd['Trip Status']=='Trip Completed']\n",
    "\n",
    "# create a dataframe '_' that maps km per day against each cab registration\n",
    "\n",
    "_ = (temp.groupby('Registration')['Leg Distance'].sum())/(temp.groupby('Registration')['Leg Date'].nunique())\n",
    "\n",
    "# now adding columns containing info about capacity, vendor and contract against each registration\n",
    "\n",
    "temp1 = pd.merge(_.reset_index(), temp.drop_duplicates(subset='Registration')[['Registration',\n",
    "                                        'Vendor', 'Contract', 'Cab Capacity']], how='inner', copy=False, on='Registration')\n",
    "temp1.rename(columns={0:'trip kms per day'}, inplace=True)\n",
    "\n",
    "# final table\n",
    "temp_tkmpd = temp1.pivot_table(values='trip kms per day', index=['Contract', 'Vendor'], columns='Cab Capacity', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty leg kms per day\n",
    "\n",
    "\n",
    "# takingonly rows where empty distance is captured\n",
    "\n",
    "temp = df_rbd.dropna(subset=['Leg Distance'])\n",
    "\n",
    "# calculating empty km per day registration wise\n",
    "\n",
    "_ = temp\n",
    "_ = (_[_['Leg Type']=='Empty Leg'].groupby('Registration')['Leg Distance'].sum())/(_[_['Leg Type']=='Empty Leg'].groupby(\n",
    "                                                'Registration')['Leg Date'].nunique())\n",
    "\n",
    "# merging the frames\n",
    "\n",
    "temp2 = pd.merge(_.reset_index(), temp.drop_duplicates(subset='Registration')[['Registration', \n",
    "                                            'Vendor', 'Contract', 'Cab Capacity']], how='inner', copy=False, on='Registration')\n",
    "temp2.rename(columns={0:'empty kms per day'}, inplace=True)\n",
    "\n",
    "# final table\n",
    "temp_ekmpd = temp2.pivot_table(values='empty kms per day', index=['Contract', 'Vendor'], columns='Cab Capacity', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total kms per day\n",
    "\n",
    "temp = temp1.merge(temp2, how='left', on='Registration', copy=False)\n",
    "temp['empty kms per day'].fillna(0, inplace=True)\n",
    "temp['total kms'] = temp['trip kms per day'] + temp['empty kms per day']\n",
    "\n",
    "del [temp1, temp2]\n",
    "\n",
    "temp_totkmpd = temp.pivot_table(values='total kms', index=['Contract_x', 'Vendor_x'], columns='Cab Capacity_x', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Duty hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-03 12:44:30.698815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sparsh Agarwal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Sparsh Agarwal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-03 12:44:41.607661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sparsh Agarwal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Sparsh Agarwal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())\n",
    "temp = df_rbd[df_rbd['Trip Status']=='Trip Completed']\n",
    "temp['timedelta'] = temp['Duty End'] - temp['Duty Start'] \n",
    "temp.drop_duplicates(subset=['Registration', 'Duty Start', 'Duty End'], inplace=True)\n",
    "\n",
    "def dutyhour(x):\n",
    "    duty_sum = temp[temp['Registration']==x]['timedelta'].sum()\n",
    "    duty_sum = duty_sum.days*86400 + duty_sum.seconds\n",
    "    no_of_days = temp[temp['Registration']==x]['Leg Date'].nunique()\n",
    "    return (duty_sum/no_of_days)/3600\n",
    "\n",
    "temp['duty hours'] = temp['Registration'].apply(dutyhour)\n",
    "\n",
    "temp.drop_duplicates(subset='Registration', inplace=True)\n",
    "temp_dh = temp.pivot_table(values='duty hours', index=['Contract', 'Vendor'], columns='Cab Capacity', aggfunc='mean')\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "###### driving hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sparsh Agarwal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\Users\\Sparsh Agarwal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Sparsh Agarwal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "C:\\Users\\Sparsh Agarwal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# trip time per day\n",
    "\n",
    "def timeonly(x):\n",
    "    format = '%H:%M'\n",
    "    if x=='':\n",
    "        return np.nan\n",
    "    else:\n",
    "        return datetime.strptime(x, format)\n",
    "\n",
    "temp = df_rbd[df_rbd['Trip Status']=='Trip Completed']\n",
    "temp['Leg Start'] = temp['Leg Start'].replace(np.nan, '').apply(timeonly)\n",
    "temp['Leg End'] = temp['Leg End'].replace(np.nan, '').apply(timeonly)\n",
    "\n",
    "def triptime(x,y):\n",
    "    if (y-x)>timedelta(0,0,0):\n",
    "        return ((y-x).seconds)/60\n",
    "    else:\n",
    "        return (((y+timedelta(1,0,0))-x).seconds)/60\n",
    "temp['timedelta'] = temp.apply(lambda x: triptime(x['Leg Start'], x['Leg End']), axis=1)\n",
    "\n",
    "def pday(x):\n",
    "    return temp[temp['Registration']==x]['timedelta'].sum()/temp[temp['Registration']==x]['Leg Date'].nunique()\n",
    "temp['trip time pd'] = temp['Registration'].apply(pday)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Contract</th>\n",
       "      <th>Vendor</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td rowspan=\"4\" valign=\"top\">MSE</td>\n",
       "      <td>Aaron Travels</td>\n",
       "      <td>56.979654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>New Way Travels</td>\n",
       "      <td>57.028423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Om Sai Travels</td>\n",
       "      <td>56.608025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Select Cabs</td>\n",
       "      <td>55.860673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td rowspan=\"3\" valign=\"top\">MSX</td>\n",
       "      <td>Aaron Travels</td>\n",
       "      <td>43.800387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>New Way Travels</td>\n",
       "      <td>12.497147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Om Sai Travels</td>\n",
       "      <td>52.801524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          timedelta\n",
       "Contract Vendor                    \n",
       "MSE      Aaron Travels    56.979654\n",
       "         New Way Travels  57.028423\n",
       "         Om Sai Travels   56.608025\n",
       "         Select Cabs      55.860673\n",
       "MSX      Aaron Travels    43.800387\n",
       "         New Way Travels  12.497147\n",
       "         Om Sai Travels   52.801524"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(temp.groupby(['Contract', 'Vendor', 'Leg Date'])['timedelta'].mean()).groupby(['Contract', 'Vendor']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commercial Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### number of trips of each contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering the trips to be included first\n",
    "\n",
    "temp = df_rbd[df_rbd['Trip Status'].apply(lambda x: True if x in trips_to_include else False)]\n",
    "temp_tc = pd.DataFrame(temp.groupby('Contract')['Trip Id'].count()).rename(columns={'Trip Id':'# of trips'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### number of cabs against vendor and contract type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking desirable trips\n",
    "temp = df_rbd[(df_rbd['Leg Date']>=commercial_start_date) & (df_rbd['Leg Date']<=commercial_end_date)]\n",
    "temp = temp[temp['Trip Status'].apply(lambda x: True if x in trips_to_include else False)]\n",
    "\n",
    "#final table, taking unique cabs\n",
    "temp_cv = temp.pivot_table(values='Registration', index='Vendor', columns='Contract', aggfunc=lambda x: len(x.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No-show, Adhoc and escort trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### no-show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift wise no show%\n",
    "\n",
    "temp = ((df_ba.groupby('Shift')['No Show'].value_counts())/(df_ba.groupby('Shift')['No Show'].count()))\n",
    "\n",
    "temp = temp.unstack().loc[temp.unstack().index.drop(labels = ['Login Adhoc', 'Logout Adhoc'])]['Yes']*100\n",
    "                                                             #'Login Non Shift', 'Logout Non Shift'])]['Yes']*100\n",
    "temp_nss = pd.DataFrame(temp)\n",
    "temp_nss = temp_nss.rename(columns={'Yes':'% no show'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekday wise no show\n",
    "\n",
    "temp = ((df_ba.groupby('Weekday')['No Show'].value_counts())/(df_ba.groupby('Weekday')['No Show'].count()))\n",
    "\n",
    "temp_nsw = pd.DataFrame(temp.unstack()['Yes']*100)\n",
    "temp_nsw = temp_nsw.rename(columns={'Yes':'% no show'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### adhoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift wise\n",
    "\n",
    "temp = df_ba[df_ba['Team']!='Escort']\n",
    "temp = ((temp.groupby('Shift')['SignIn Type'].value_counts())/(temp.groupby('Shift')['SignIn Type'].count()))\n",
    "\n",
    "temp_ads = pd.DataFrame(temp.unstack()['Adhoc']*100)\n",
    "temp_ads = temp_ads.rename(columns={'Adhoc':'% of adhocs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekday wise\n",
    "\n",
    "temp = df_ba[df_ba['Team']!='Escort']\n",
    "temp = ((temp.groupby('Weekday')['SignIn Type'].value_counts())/(temp.groupby('Weekday')['SignIn Type'].count()))\n",
    "\n",
    "temp_adw = pd.DataFrame(temp.unstack()['Adhoc']*100)\n",
    "temp_adw = temp_adw.rename(columns={'Adhoc':'% of adhocs'})       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### escort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift wise distribution\n",
    "\n",
    "temp = ((df_ba[df_ba['Team']=='Escort'].pivot_table(values='Trip ID', index='Shift', aggfunc=lambda x: x.nunique()))/(\n",
    "    df_ba[df_ba['Employee Status']=='Boarded'].pivot_table(values='Trip ID', index='Shift', aggfunc=lambda x: x.nunique()))).dropna()\n",
    "temp_ess = (temp*100).rename(columns={'Trip ID':'% of escort trips'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weekday wise distribution\n",
    "\n",
    "temp = ((df_ba[df_ba['Team']=='Escort'].pivot_table(values='Trip ID', index='Weekday', aggfunc=lambda x: x.nunique()))/(\n",
    "    df_ba[df_ba['Employee Status']=='Boarded'].pivot_table(values='Trip ID', index='Weekday', aggfunc=lambda x: x.nunique()))).dropna()\n",
    "temp_esw = (temp*100).rename(columns={'Trip ID':'% of escort trips'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'escort' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-91d11f13096a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#escort = [df_ba.loc[y, 'Trip ID'] for y in list(df_ba.index) if df_ba.loc[y, 'Team']=='Escort']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_ba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_ba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Trip ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mescort\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Employee Status'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Boarded'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Team'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m'Escort'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0my_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Direction'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Logout'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4040\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4041\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4042\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4044\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-39-91d11f13096a>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#escort = [df_ba.loc[y, 'Trip ID'] for y in list(df_ba.index) if df_ba.loc[y, 'Team']=='Escort']\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf_ba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_ba\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Trip ID'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mescort\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mtemp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Employee Status'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Boarded'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Team'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;34m'Escort'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0my_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtemp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Direction'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Logout'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'escort' is not defined"
     ]
    }
   ],
   "source": [
    "# notional escort savings\n",
    "\n",
    "user_defined_deviation_limit = 2\n",
    "\n",
    "# taking info of all the escort trips only logout and login wise\n",
    "\n",
    "#escort = [df_ba.loc[y, 'Trip ID'] for y in list(df_ba.index) if df_ba.loc[y, 'Team']=='Escort']\n",
    "temp = df_ba[df_ba['Trip ID'].apply(lambda x: x in escort)]\n",
    "temp = temp[(temp['Employee Status']=='Boarded') & (temp['Team']!='Escort')]\n",
    "y_out = temp[temp['Direction']=='Logout'].copy()\n",
    "y_in = temp[temp['Direction']=='Login'].copy()\n",
    "\n",
    "# working on the logout trips\n",
    "\n",
    "y_out = y_out.join(y_out.shift(1), rsuffix='_lag', how='left')\n",
    "y_out = y_out[(y_out['Trip ID']!=y_out['Trip ID'].shift(1)) | (y_out['Trip ID']!=y_out['Trip ID'].shift(2))]\n",
    "# first male\n",
    "print(sum((y_out['Trip ID']!=y_out['Trip ID_lag']) & (y_out['Gender']=='Male')))\n",
    "# distance difference of buddy less than 0\n",
    "print(sum(y_out[(y_out['Trip ID']==y_out['Trip ID_lag']) & (y_out['Gender']=='Male') & \n",
    "          (y_out['Gender_lag']=='Female')]['Distance Travelled(KM)'] >\n",
    "    y_out[(y_out['Trip ID']==y_out['Trip ID_lag']) & (y_out['Gender']=='Male') & \n",
    "          (y_out['Gender_lag']=='Female')]['Distance Travelled(KM)_lag']))\n",
    "# possible savings based on the user defined limit\n",
    "print(sum((y_out[(y_out['Trip ID']==y_out['Trip ID_lag']) & (y_out['Gender']=='Male') & \n",
    "          (y_out['Gender_lag']=='Female')]['Distance Travelled(KM)_lag'] -\n",
    "    y_out[(y_out['Trip ID']==y_out['Trip ID_lag']) & (y_out['Gender']=='Male') & \n",
    "          (y_out['Gender_lag']=='Female')]['Distance Travelled(KM)']) <= user_defined_deviation_limit/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(output_path) as writer:\n",
    "    temp_su.to_excel(writer, sheet_name='Fleet Mix', startrow=2)\n",
    "    temp_dev.to_excel(writer, sheet_name='Fleet Mix', startrow=2, startcol=len(temp_su.columns)+4)\n",
    "    temp_fm.to_excel(writer, sheet_name='Fleet Mix', startrow=2, startcol=len(temp_su.columns)+len(temp_dev.columns)+8)\n",
    "    temp_td.to_excel(writer, sheet_name='Bill Model', startrow=2)\n",
    "    temp_tpd.to_excel(writer, sheet_name='Bill Model', startrow=2, startcol=len(temp_td.columns)+4)\n",
    "    temp_tkmpd.to_excel(writer, sheet_name='Bill Model', startrow=2, startcol=len(temp_td.columns)+len(temp_tpd.columns)+8)\n",
    "    temp_ekmpd.to_excel(writer, sheet_name='Bill Model', startrow=2, startcol=len(temp_td.columns)+len(temp_tpd.columns)+len(temp_tkmpd.columns)+12)\n",
    "    temp_totkmpd.to_excel(writer, sheet_name='Bill Model', startrow=2, startcol=len(temp_td.columns)+len(temp_tpd.columns)+len(temp_tkmpd.columns)+len(temp_ekmpd.columns)+16)\n",
    "    temp_dh.to_excel(writer, sheet_name='Bill Model', startrow=2, startcol=len(temp_td.columns)+len(temp_tpd.columns)+len(temp_tkmpd.columns)+len(temp_ekmpd.columns)+len(temp_totkmpd.columns)+20)\n",
    "    temp_tc.to_excel(writer, sheet_name='Commercial', startrow=2)\n",
    "    temp_cv.to_excel(writer, sheet_name='Commercial', startrow=2, startcol=len(temp_tc.columns)+4)\n",
    "    temp_nss.to_excel(writer, sheet_name='NoShow', startrow=2)\n",
    "    temp_nsw.to_excel(writer, sheet_name='NoShow', startrow=2, startcol=len(temp_nss.columns)+4)\n",
    "    temp_ads.to_excel(writer, sheet_name='Adhoc', startrow=2)\n",
    "    temp_adw.to_excel(writer, sheet_name='Adhoc', startrow=2, startcol=len(temp_ads.columns)+4)\n",
    "    temp_ess.to_excel(writer, sheet_name='Escort', startrow=2)\n",
    "    temp_esw.to_excel(writer, sheet_name='Escort', startrow=2, startcol=len(temp_ess.columns)+4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = datetime.strptime(\"12-02-2020 23:45\", \"%d-%m-%Y %H:%M\")\n",
    "y = datetime.strptime(\"13-02-2020 00:15\", \"%d-%m-%Y %H:%M\")\n",
    "a = y-x\n",
    "a<timedelta(0,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y-x).seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a + datetime.timedelta(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.days%2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(266154/86400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = datetime.timedelta(0, 86399)\n",
    "q = datetime.timedelta(1, 51)\n",
    "z = p+q\n",
    "z = z.days*86400 + z.seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 1, 0, 1]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0,1]*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = xlsxwriter.Workbook('D:/solutioning/amz-hyd/hello.xlsx')\n",
    "worksheet = workbook.add_worksheet('Sheet exp')\n",
    "worksheet.write('A1', 'Hello World')\n",
    "workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mix</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>mix</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>mix</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>rag</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>rag</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>rag</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1  col2  col3\n",
       "0  mix     0    11\n",
       "1  mix     1    12\n",
       "2  mix     0    13\n",
       "3  rag     1    14\n",
       "4  rag     0    15\n",
       "5  rag     1    16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = pd.DataFrame({'col1':['mix', 'mix', 'mix', 'rag', 'rag', 'rag'], 'col2':[0,1]*3, 'col3':[11,12,13,14,15,16]})\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mix</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>rag</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1  col2  col3\n",
       "0  mix     0    11\n",
       "3  rag     1    14"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.drop_duplicates(subset='col1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mix</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>mix</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>rag</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>rag</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1  col2  col3\n",
       "0  mix     0    11\n",
       "1  mix     1    12\n",
       "3  rag     1    14\n",
       "4  rag     0    15"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.drop_duplicates(subset=['col1', 'col2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>mix</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>mix</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>rag</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>rag</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  col1  col2  col3\n",
       "0  mix     0    11\n",
       "1  mix     1    12\n",
       "3  rag     1    14\n",
       "4  rag     0    15"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.drop_duplicates(subset=['col2', 'col1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-30 17:53:39.019676\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Weekday\n",
       "Fri    1796.00\n",
       "Mon    2187.50\n",
       "Sat      24.00\n",
       "Sun       0.00\n",
       "Thu    2462.00\n",
       "Tue    2472.50\n",
       "Wed    2430.25\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df_rbd[df_rbd['Trip Status'].apply(lambda x: x in trips_to_include)]\n",
    "temp.groupby('Weekday')['Planned Trip Employees'].sum()/temp.groupby('Weekday')['Leg Date'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Leg Date\n",
       "2020-02-01       6.0\n",
       "2020-02-03    2200.0\n",
       "2020-02-04    2516.0\n",
       "2020-02-05    2480.0\n",
       "2020-02-06    2466.0\n",
       "2020-02-07    2253.0\n",
       "2020-02-08      35.0\n",
       "2020-02-09       0.0\n",
       "2020-02-10    2194.0\n",
       "2020-02-11    2467.0\n",
       "2020-02-12    2222.0\n",
       "2020-02-13    2477.0\n",
       "2020-02-14    2128.0\n",
       "2020-02-15      18.0\n",
       "2020-02-16       0.0\n",
       "2020-02-17    2065.0\n",
       "2020-02-18    2473.0\n",
       "2020-02-19    2539.0\n",
       "2020-02-20    2353.0\n",
       "2020-02-21     497.0\n",
       "2020-02-22      18.0\n",
       "2020-02-23       0.0\n",
       "2020-02-24    2291.0\n",
       "2020-02-25    2434.0\n",
       "2020-02-26    2480.0\n",
       "2020-02-27    2552.0\n",
       "2020-02-28    2306.0\n",
       "2020-02-29      43.0\n",
       "Name: Planned Trip Employees, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = df_rbd[df_rbd['Trip Status'].apply(lambda x: x in trips_to_include)]\n",
    "temp = temp.groupby('Leg Date')['Planned Trip Employees'].sum()\n",
    "print(len(temp[temp>=0.3*temp.max()]))\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
